{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c287930",
   "metadata": {},
   "source": [
    "# Assignment 11 draft (NOT FINALIZED)\n",
    "\n",
    "Please fill in blanks in the *Answer* sections of this notebook. To check your answer for a problem, run the Setup, Answer, and Result sections. DO NOT MODIFY SETUP OR RESULT CELLS. See the [README](https://github.com/mortonne/datascipsych) for instructions on setting up a Python environment to run this notebook.\n",
    "\n",
    "Write your answers for each problem. Then restart the kernel, run all cells, and then save the notebook. Upload your notebook to Canvas.\n",
    "\n",
    "If you get stuck, read through the other notebooks in this directory, ask us for help in class, or ask other students for help in class or on the weekly discussion board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28c98f4",
   "metadata": {},
   "source": [
    "## Problem: one-sample t-test (3 points)\n",
    "\n",
    "### Run one-sample t-test (2 points)\n",
    "Given the `targets` DataFrame defined below, use `pg.ttest` to run a one-sample t-test assessing whether the mean response is greater than 0.5. Assign the results DataFrame to a variable called ttest1.\n",
    "\n",
    "### interpret the results (1 point)\n",
    "Answer the questions about interpretation of the t-test (0.5 point per question). Edit the markdown cell (you can double-click on it to edit it, or click on the pencil icon) to add your answer below each question. Then click on the check icon to switch back to rendered text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de475bad",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "340d1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pingouin as pg\n",
    "from IPython.display import display\n",
    "data = pl.read_csv(\"gen_recog.csv\")\n",
    "targets = (\n",
    "    data.filter(pl.col(\"trial_type\") == \"target\")\n",
    "    .group_by(\"subject\")\n",
    "    .agg(pl.col(\"response\").mean())\n",
    "    .sort(\"subject\")\n",
    ")\n",
    "ttest1 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec2c29b",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c900ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0a870b",
   "metadata": {},
   "source": [
    "> Was the mean response significantly greater than 0.5 (yes or no)?\n",
    "\n",
    "[answer here]\n",
    "\n",
    "> What was the effect size?\n",
    "\n",
    "[answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eb7759",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48fdd032",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [ttest1]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    display(ttest1)\n",
    "    \n",
    "    # this should not throw any errors\n",
    "    assert round(ttest1.loc[\"T-test\", \"T\"], 2) == 31.15\n",
    "    assert ttest1.loc[\"T-test\", \"dof\"] == 49\n",
    "    assert ttest1.loc[\"T-test\", \"alternative\"] == \"greater\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c81f63e",
   "metadata": {},
   "source": [
    "## Problem: two-sample paired t-test (3 points)\n",
    "\n",
    "### Run paired t-test (2 points)\n",
    "Given the `pivot` DataFrame defined below, use `pg.ttest` to run a two-sample paired t-test assessing whether participants were more likely to respond \"old\" for targets than for lures. Assign the results DataFrame to a variable called ttest2.\n",
    "\n",
    "### Interpret the results (1 point)\n",
    "Answer the questions about interpretation of the t-test (0.5 point per question). Edit the markdown cell (you can double-click on it to edit it, or click on the pencil icon) to add your answer below each question. Then click on the check icon to switch back to rendered text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb860fe",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "489abd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>subject</th><th>target</th><th>lure</th></tr><tr><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;subj01&quot;</td><td>0.745</td><td>0.208333</td></tr><tr><td>&quot;subj02&quot;</td><td>0.716667</td><td>0.156667</td></tr><tr><td>&quot;subj03&quot;</td><td>0.79</td><td>0.16</td></tr><tr><td>&quot;subj04&quot;</td><td>0.67</td><td>0.13</td></tr><tr><td>&quot;subj05&quot;</td><td>0.741667</td><td>0.145</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────┬──────────┬──────────┐\n",
       "│ subject ┆ target   ┆ lure     │\n",
       "│ ---     ┆ ---      ┆ ---      │\n",
       "│ str     ┆ f64      ┆ f64      │\n",
       "╞═════════╪══════════╪══════════╡\n",
       "│ subj01  ┆ 0.745    ┆ 0.208333 │\n",
       "│ subj02  ┆ 0.716667 ┆ 0.156667 │\n",
       "│ subj03  ┆ 0.79     ┆ 0.16     │\n",
       "│ subj04  ┆ 0.67     ┆ 0.13     │\n",
       "│ subj05  ┆ 0.741667 ┆ 0.145    │\n",
       "└─────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot = data.pivot(\"trial_type\", index=\"subject\", values=\"response\", aggregate_function=\"mean\")\n",
    "ttest2 = None\n",
    "pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18942056",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e5ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba8d2c5",
   "metadata": {},
   "source": [
    "> Were target responses significantly greater than lure responses (yes or no)?\n",
    "\n",
    "[answer here]\n",
    "\n",
    "> What was the t-statistic?\n",
    "\n",
    "[answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd54436b",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9536c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [ttest2]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    display(ttest2)\n",
    "    \n",
    "    # this should not throw any errors\n",
    "    assert round(ttest2.loc[\"T-test\", \"T\"], 2) == 75.86\n",
    "    assert ttest2.loc[\"T-test\", \"dof\"] == 49\n",
    "    assert ttest2.loc[\"T-test\", \"alternative\"] == \"greater\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77622589",
   "metadata": {},
   "source": [
    "## Problem: one-way repeated-measures ANOVA (3 points)\n",
    "\n",
    "### Run one-way ANOVA (2 points)\n",
    "Given the `m_st` DataFrame defined below, use `pg.rm_anova` to run a one-way repeated-measures ANOVA assessing whether performance varies with study time. Assign the result to a variable called `anova1`.\n",
    "\n",
    "### interpret the results (1 point)\n",
    "Answer the questions about interpretation of the ANOVA (0.5 point per question). Edit the markdown cell (you can double-click on it to edit it, or click on the pencil icon) to add your answer below each question. Then click on the check icon to switch back to rendered text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fff812",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f8f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_st = (\n",
    "    data.pivot(\"trial_type\", index=[\"subject\", \"study_time\"], values=\"response\", aggregate_function=\"mean\")\n",
    "    .select(\n",
    "        \"subject\",\n",
    "        \"study_time\",\n",
    "        performance=pl.col(\"target\") - pl.col(\"lure\")\n",
    "    )\n",
    ")\n",
    "anova1 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae35d3",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afb00774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b6964d",
   "metadata": {},
   "source": [
    "> Did study time significantly affect performance (yes or no)?\n",
    "\n",
    "[answer here]\n",
    "\n",
    "> What was the effect size?\n",
    "\n",
    "[answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ab3c7",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cfefa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [anova1]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    display(anova1)\n",
    "    \n",
    "    # this should not throw any errors\n",
    "    assert round(anova1.loc[0, \"F\"], 2) == 224.36\n",
    "    assert anova1.loc[0, \"ddof1\"] == 2\n",
    "    assert anova1.loc[0, \"ddof2\"] == 98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf0620b",
   "metadata": {},
   "source": [
    "## Problem: two-way repeated-measures ANOVA (3 points)\n",
    "\n",
    "### Run two-way ANOVA (1.5 points) \n",
    "Given the `m_st_it` DataFrame defined below, use `pg.rm_anova` to run a two-way repeated-measures ANOVA assessing whether performance varies with study time and item type. Assign the result to a variable called `anova2`.\n",
    "\n",
    "You will probably get some `FutureWarning` messages printed when you run `pg.rm_anova`. This is normal.\n",
    "\n",
    "### Interpret the results (1.5 points)\n",
    "Answer the questions about interpretation of the ANOVA (0.5 point per question). Edit the markdown cell (you can double-click on it to edit it, or click on the pencil icon) to add your answer below each question. Then click on the check icon to switch back to rendered text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41774342",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e9d02aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>subject</th><th>study_time</th><th>item_type</th><th>performance</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;subj01&quot;</td><td>1</td><td>&quot;word&quot;</td><td>0.35</td></tr><tr><td>&quot;subj01&quot;</td><td>1</td><td>&quot;picture&quot;</td><td>0.54</td></tr><tr><td>&quot;subj01&quot;</td><td>2</td><td>&quot;word&quot;</td><td>0.33</td></tr><tr><td>&quot;subj01&quot;</td><td>2</td><td>&quot;picture&quot;</td><td>0.56</td></tr><tr><td>&quot;subj01&quot;</td><td>4</td><td>&quot;word&quot;</td><td>0.7</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────┬────────────┬───────────┬─────────────┐\n",
       "│ subject ┆ study_time ┆ item_type ┆ performance │\n",
       "│ ---     ┆ ---        ┆ ---       ┆ ---         │\n",
       "│ str     ┆ i64        ┆ str       ┆ f64         │\n",
       "╞═════════╪════════════╪═══════════╪═════════════╡\n",
       "│ subj01  ┆ 1          ┆ word      ┆ 0.35        │\n",
       "│ subj01  ┆ 1          ┆ picture   ┆ 0.54        │\n",
       "│ subj01  ┆ 2          ┆ word      ┆ 0.33        │\n",
       "│ subj01  ┆ 2          ┆ picture   ┆ 0.56        │\n",
       "│ subj01  ┆ 4          ┆ word      ┆ 0.7         │\n",
       "└─────────┴────────────┴───────────┴─────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_st_it = (\n",
    "    data.pivot(\"trial_type\", index=[\"subject\", \"study_time\", \"item_type\"], values=\"response\", aggregate_function=\"mean\")\n",
    "    .select(\n",
    "        \"subject\",\n",
    "        \"study_time\",\n",
    "        \"item_type\",\n",
    "        performance=pl.col(\"target\") - pl.col(\"lure\")\n",
    "    )\n",
    ")\n",
    "anova2 = None\n",
    "m_st_it.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b599824c",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62dec8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d6e9d",
   "metadata": {},
   "source": [
    "> Did you observe a significant main effect of study time (yes or no)?\n",
    "\n",
    "[answer here]\n",
    "\n",
    "> Did you observe a significant main effect of item type (yes or no)?\n",
    "\n",
    "[answer here]\n",
    "\n",
    "> Did you observe a significant interaction effect (yes or no)?\n",
    "\n",
    "[answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19b6bc7",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d7a7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [anova2]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    display(anova2)\n",
    "    \n",
    "    # this should not throw any errors\n",
    "    assert round(anova2.loc[0, \"F\"], 2) == 224.36\n",
    "    assert round(anova2.loc[1, \"F\"], 2) == 282.50\n",
    "    assert round(anova2.loc[2, \"F\"], 2) == 5.53\n",
    "    assert anova2.loc[0, \"ddof1\"] == 2\n",
    "    assert anova2.loc[0, \"ddof2\"] == 98\n",
    "    assert anova2.loc[1, \"ddof1\"] == 1\n",
    "    assert anova2.loc[1, \"ddof2\"] == 49\n",
    "    assert anova2.loc[2, \"ddof1\"] == 2\n",
    "    assert anova2.loc[2, \"ddof2\"] == 98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aae7050",
   "metadata": {},
   "source": [
    "## Problem (graduate students): power analysis (2 points)\n",
    "\n",
    "Read about [power analysis](https://en.wikipedia.org/wiki/Power_(statistics)) and  using the Pingouin `power_ttest` [function](https://pingouin-stats.org/build/html/generated/pingouin.power_ttest.html). The probability of making a false-positive error is often called $\\alpha$. NHST is designed to control this probability. It is also important to consider false-negative errors. The probability of a false-negative error is called $\\beta$. The *statistical power* is the probability of detecting an effect if it is present, defined as $1 - \\beta$. Pingouin, and other statistical packages, allow us to estimate the statistical power of a given inferential test, based on the effect size and sample size.\n",
    "\n",
    "Calculate the statistical power for a two-sample t-test if $d=0.6$ and $n=20$. Assign it to a variable called `power`.\n",
    "\n",
    "Calculate the required sample size for a paired t-test if $d=0.45$ and $\\mathrm{power}=0.8$, and the alternative hypothesis is `\"greater\"`. Assign it to a variable called `n`.\n",
    "\n",
    "Calculate the effect size achieved for a one-sample t-test given $n=30$, $\\mathrm{power}=0.8$, and $\\alpha=0.05$. Assign it to a variable called `d`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b1a6f",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dbf5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "power = None\n",
    "n = None\n",
    "d = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a77fb25",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "735d29e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b1c596",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89b87c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [power, n, d]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    print(power, n, d)\n",
    "    \n",
    "    # this should not throw any errors\n",
    "    assert round(power, 2) == 0.46\n",
    "    assert round(n, 2) == 31.93\n",
    "    assert round(d, 2) == 0.53"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d64270",
   "metadata": {},
   "source": [
    "## Problem (graduate students): pairwise tests (2 points)\n",
    "\n",
    "The [pairwise_tests](https://pingouin-stats.org/build/html/generated/pingouin.pairwise_tests.html#pingouin.pairwise_tests) function can be used to compare all individual groups of a given factor. It includes various methods (defined using the `padjust` input) for dealing with the [multiple comparisons problem](https://en.wikipedia.org/wiki/Multiple_comparisons_problem). When many statistical tests are run, the probability of there being at least one false positive increases rapidly. Various methods have been developed to control the rate of false positives while keeping statistical power relatively high.\n",
    "\n",
    "Given the `m_st` DataFrame, which has the average recognition memory performance for each subject and study time (1 2, or 4 seconds), use `pg.pairwise_tests` to test all pairwise comparisons between study time conditions. Use the FDR-BH method (false-discovery rate control using the Benjamini–Hochberg procedure) to calculate adjusted p-values. Assign the resulting DataFrame to a variable called `pw_tests`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f3a0d5",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf8621f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_st.head()\n",
    "pw_tests = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd6a228",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ed35047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00df66b",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fa08037",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [pw_tests]\n",
    "if all([v is not None for v in vars]):\n",
    "    # this should print your variables\n",
    "    display(pw_tests)\n",
    "    \n",
    "    # this should not throw any errors\n",
    "    assert (pw_tests[\"p-adjust\"] == \"fdr_bh\").all()\n",
    "    assert round(pw_tests.loc[0, \"T\"], 2) == -16.33\n",
    "    assert pw_tests.loc[0, \"dof\"] == 49\n",
    "    assert round(pw_tests.loc[1, \"T\"], 2) == -18.80\n",
    "    assert pw_tests.loc[1, \"dof\"] == 49\n",
    "    assert round(pw_tests.loc[2, \"T\"], 2) == -4.65\n",
    "    assert pw_tests.loc[0, \"dof\"] == 49"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascipsych",
   "language": "python",
   "name": "datascipsych"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
